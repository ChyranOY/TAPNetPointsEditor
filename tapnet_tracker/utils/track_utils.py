#!/usr/bin/env python3
"""
Track processing utilities for TAPNet Tracker.

Contains functions for generating query points, processing track data, and saving tracks.
"""

import os
import numpy as np
import torch
from typing import List, Tuple, Optional


def generate_query_points(num_points: int, method: str = "manual", 
                         manual_points: Optional[List[Tuple[float, float]]] = None) -> np.ndarray:
    """
    ç”ŸæˆæŸ¥è¯¢ç‚¹
    
    Args:
        num_points: å…¼å®¹æ€§å‚æ•°ï¼ˆåœ¨manualæ¨¡å¼ä¸‹è¢«å¿½ç•¥ï¼‰
        method: ç”Ÿæˆæ–¹æ³• ("manual")
        manual_points: æ‰‹åŠ¨æŒ‡å®šçš„ç‚¹åˆ—è¡¨ (å½’ä¸€åŒ–åæ ‡ï¼ŒèŒƒå›´0-1)
        
    Returns:
        query_points: shapeä¸º[actual_points, 3]çš„numpyæ•°ç»„ï¼Œæ ¼å¼ä¸º[time, y, x]
    """
    if method == "manual" and manual_points:
        # å¤„ç†æ‰‹åŠ¨ç‚¹ (256åæ ‡ç³») - æ¢å¤åŸç‰ˆ[visibility, y, x]æ ¼å¼
        click_coords = []
        for x, y in manual_points:
            # TAPNextæ¨¡å‹æœŸæœ›åæ ‡æ ¼å¼: [visibility, y, x] - ä¸¥æ ¼æŒ‰åŸç‰ˆvideo2track.pyå®ç°
            click_coords.append([0.0, float(y), float(x)])  # [visibility, y, x]
        
        query_points = np.array(click_coords, dtype=np.float32)
        
        print(f"ğŸ¯ Manualæ¨¡å¼: ä½¿ç”¨æ‰‹åŠ¨é€‰æ‹©çš„ {len(manual_points)} ä¸ªç‚¹")
        print(f"   åŸå§‹256åæ ‡: {[(x, y) for x, y in manual_points]}")
        print(f"   è½¬æ¢ä¸º[visibility,y,x]: {[(t, y, x) for t, y, x in click_coords]}")
        print(f"   æŸ¥è¯¢ç‚¹æ ¼å¼: [visibility, y, x] - ä¸¥æ ¼æŒ‰åŸç‰ˆå®ç°")
        print(f"   æŸ¥è¯¢ç‚¹å½¢çŠ¶: {query_points.shape}")
        
        # æ·»åŠ batchç»´åº¦ [1, points, 3]
        query_points_with_batch = query_points[None]
        print(f"   æ·»åŠ batchç»´åº¦å: {query_points_with_batch.shape}")
        return query_points_with_batch
    else:
        raise ValueError("åªæ”¯æŒmanualæ¨¡å¼ï¼Œè¯·é€šè¿‡ç‚¹å‡»å›¾åƒé€‰æ‹©è½¨è¿¹ç‚¹")


def scale_tracks_to_original_size(tracks: np.ndarray, target_size: Tuple[int, int], 
                                 original_size: Tuple[int, int]) -> np.ndarray:
    """
    å°†è½¨è¿¹åæ ‡ä»ç›®æ ‡å°ºå¯¸ç¼©æ”¾åˆ°åŸå§‹å°ºå¯¸
    
    Args:
        tracks: è½¨è¿¹æ•°æ®ï¼Œshapeä¸º[points, frames, 2]
        target_size: ç›®æ ‡å°ºå¯¸ (width, height)
        original_size: åŸå§‹å°ºå¯¸ (width, height)
        
    Returns:
        scaled_tracks: ç¼©æ”¾åçš„è½¨è¿¹æ•°æ®
    """
    target_w, target_h = target_size
    original_w, original_h = original_size
    
    # è®¡ç®—ç¼©æ”¾å› å­
    scale_x = original_w / target_w
    scale_y = original_h / target_h
    
    # å¤åˆ¶è½¨è¿¹æ•°æ®ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    scaled_tracks = tracks.copy()
    
    # ç¼©æ”¾åæ ‡ - ä¿®æ­£ï¼šä»è°ƒè¯•ä¿¡æ¯ç¡®è®¤[0]æ˜¯xåæ ‡ï¼Œ[1]æ˜¯yåæ ‡
    scaled_tracks[:, :, 0] *= scale_x  # xåæ ‡ (tracks[..., 0])
    scaled_tracks[:, :, 1] *= scale_y  # yåæ ‡ (tracks[..., 1])
    
    print(f"Track coordinate scaling:")
    print(f"  - Target size: {target_size}")
    print(f"  - Original size: {original_size}")
    print(f"  - Scale factors: x={scale_x:.2f}, y={scale_y:.2f}")
    print(f"  - Correction: [0]=x coordinate uses scale_x, [1]=y coordinate uses scale_y")
    
    return scaled_tracks


def save_tracks_as_pth(tracks: np.ndarray, visibles: np.ndarray, output_path: str, quant_multi: int = 8):
    """
    å°†è½¨è¿¹æ•°æ®ä¿å­˜ä¸º.pthæ–‡ä»¶ï¼Œè¾“å‡ºæ ¼å¼ä¸º[points, frames, batch, 3]
    å…¶ä¸­æœ€åä¸€ç»´ä¸º(visibility, y, x)
    
    Args:
        tracks: è½¨è¿¹æ•°æ®ï¼Œshapeä¸º[batch, num_points, num_frames, 2] - (x, y)
        visibles: å¯è§æ€§æ•°æ®ï¼Œshapeä¸º[batch, num_points, num_frames, 1]
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        quant_multi: é‡åŒ–å› å­
    """
    
    print(f"ğŸ“Š è¾“å…¥æ•°æ®å½¢çŠ¶:")
    print(f"  - tracks: {tracks.shape} (batch, points, frames, 2)")
    print(f"  - visibles: {visibles.shape} (batch, points, frames, 1)")
    
    # ä¿æŒtracksåæ ‡åŸå§‹é¡ºåº: (x, y)
    # æŒ‰ç…§(x, y, visibility)çš„é¡ºåºåˆå¹¶æ•°æ®
    # tracks: [batch, points, frames, 2] - (x, y)
    # visibles: [batch, points, frames, 1]
    combined_tracks = np.concatenate([tracks, visibles], axis=-1)  # [batch, points, frames, 3]
    
    print(f"ğŸ“ åˆå¹¶åæ•°æ®:")
    print(f"  - å½¢çŠ¶: {combined_tracks.shape} (batch, points, frames, 3)")
    print(f"  - ç¬¬3ç»´é¡ºåº: (x, y, visibility)")
    
    # è½¬æ¢ç»´åº¦: [batch, points, frames, 3] -> [points, frames, batch, 3]
    combined_tracks = np.transpose(combined_tracks, (1, 2, 0, 3))
    
    # é‡åŒ–å¤„ç†
    combined_tracks_quantized = combined_tracks * quant_multi
    combined_tracks_quantized = combined_tracks_quantized.astype(np.float32)
    
    print(f"ğŸ’¾ Final saved data:")
    print(f"  - Data shape: {combined_tracks_quantized.shape} [points, frames, batch, 3]")
    print(f"  - Number of points: {combined_tracks_quantized.shape[0]}")
    print(f"  - Number of frames: {combined_tracks_quantized.shape[1]}")
    print(f"  - Batch count: {combined_tracks_quantized.shape[2]}")
    print(f"  - 3rd dimension: (x, y, visibility)")
    print(f"  - Data range: [{combined_tracks_quantized.min():.2f}, {combined_tracks_quantized.max():.2f}]")
    print(f"  - X coordinate range: [{combined_tracks_quantized[:, :, :, 0].min():.1f}, {combined_tracks_quantized[:, :, :, 0].max():.1f}]")
    print(f"  - Y coordinate range: [{combined_tracks_quantized[:, :, :, 1].min():.1f}, {combined_tracks_quantized[:, :, :, 1].max():.1f}]")
    print(f"  - Visibility range: [{combined_tracks_quantized[:, :, :, 2].min():.1f}, {combined_tracks_quantized[:, :, :, 2].max():.1f}]")
    
    # åˆ›å»ºä¸´æ—¶npzæ–‡ä»¶å¹¶ä¿å­˜
    import tempfile
    with tempfile.NamedTemporaryFile(suffix='.npz', delete=False) as npz_file:
        npz_path = npz_file.name
    
    # ä¿å­˜ä¸ºnpzæ ¼å¼
    np.savez_compressed(npz_path, array=combined_tracks_quantized)
    
    # è¯»å–npzæ–‡ä»¶çš„å­—èŠ‚æ•°æ®
    with open(npz_path, 'rb') as f:
        compressed_data = f.read()
    
    # ä¿å­˜ä¸º.pthæ ¼å¼
    torch.save(compressed_data, output_path)
    
    # æ¸…ç†ä¸´æ—¶npzæ–‡ä»¶
    os.unlink(npz_path)
    
    print(f"âœ… Tracks saved to: {output_path}")
    
    return output_path


def unzip_to_array(data: bytes, key: str = "array") -> np.ndarray:
    """ä»å‹ç¼©æ•°æ®ä¸­è§£å‹æ•°ç»„"""
    import io
    import tempfile
    import zipfile
    
    if isinstance(data, bytes):
        # å¦‚æœæ˜¯bytesï¼Œå…ˆä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶å†åŠ è½½
        with tempfile.NamedTemporaryFile(suffix='.npz', delete=False) as tmp_file:
            tmp_file.write(data)
            tmp_path = tmp_file.name
        
        try:
            # åŠ è½½npzæ–‡ä»¶
            loaded = np.load(tmp_path, allow_pickle=False)
            if hasattr(loaded, 'files'):
                # å¦‚æœæ˜¯npzæ–‡ä»¶ï¼Œè·å–æŒ‡å®šçš„é”®
                array = loaded[key]
            else:
                # å¦‚æœæ˜¯å•ä¸ªæ•°ç»„
                array = loaded
            return array
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)
    else:
        # å¦‚æœå·²ç»æ˜¯æ•°ç»„ï¼Œç›´æ¥è¿”å›
        return data


def scale_coordinates_to_target_size(tracks_coords, original_size, target_size):
    """å°†åæ ‡ä»åŸå§‹å°ºå¯¸ç¼©æ”¾åˆ°ç›®æ ‡å°ºå¯¸"""
    original_w, original_h = original_size
    target_w, target_h = target_size
    
    # è®¡ç®—ç¼©æ”¾å› å­
    scale_x = target_w / original_w
    scale_y = target_h / original_h
    
    # ç¼©æ”¾åæ ‡
    scaled_coords = tracks_coords.copy()
    scaled_coords[:, :, 0] *= scale_x  # xåæ ‡
    scaled_coords[:, :, 1] *= scale_y  # yåæ ‡
    
    return scaled_coords 